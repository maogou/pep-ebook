package downloader

import (
	"errors"
	"fmt"
	"io"
	"math/rand"
	"net/http"
	"os"
	"regexp"
	"strings"
	"time"

	"github.com/urfave/cli/v2"
)

type Download struct {
	BaseHandler
}

var _ Chain = (*Download)(nil)
var (
	curlRegex      = regexp.MustCompile(`curl '([^']+)'`)
	bookIDRegex    = regexp.MustCompile(`book\.pep\.com\.cn/(\d+)`)
	urlFormatRegex = regexp.MustCompile(`(\d+)/files/mobile/(\d+)\.jpg`)
	headerRegex    = regexp.MustCompile(`-H '([^:]+):\s*([^']+)'`)
	cookieRegex    = regexp.MustCompile(`-(?:-cookie|b) '([^']+)'`)
)

type CurlData struct {
	PageURLFormat string
	ReferFormat   string
	Headers       http.Header
}

func MakeBookURL(bookID string) string {
	return fmt.Sprintf("https://book.pep.com.cn/%s/mobile/index.html", bookID)
}

func ParseCURL(curl string) (CurlData, error) {
	data := CurlData{Headers: make(http.Header)}

	// æå– URL å’Œ book_id
	urlMatch := curlRegex.FindStringSubmatch(curl)
	if len(urlMatch) < 2 {
		return data, fmt.Errorf("invalid URL format")
	}
	originalURL := urlMatch[1]

	// æå– book_id
	bookID := ""
	bookIDMatch := bookIDRegex.FindStringSubmatch(originalURL)
	if len(bookIDMatch) >= 2 {
		bookID = bookIDMatch[1]
	}

	// ç”Ÿæˆ PageURLFormat
	data.PageURLFormat = urlFormatRegex.ReplaceAllString(originalURL, "%s/files/mobile/%d.jpg")

	// è§£æ Headers
	headerMatches := headerRegex.FindAllStringSubmatch(curl, -1)

	for _, match := range headerMatches {
		if len(match) >= 3 {
			key := strings.TrimSpace(match[1])
			value := strings.TrimSpace(strings.Trim(match[2], `"`)) // ç§»é™¤å€¼ä¸­çš„åŒå¼•å·
			data.Headers.Add(key, value)
		}
	}

	// è§£æ Cookie å‚æ•°
	cookieMatches := cookieRegex.FindAllStringSubmatch(curl, -1)
	for _, match := range cookieMatches {
		if len(match) >= 2 {
			cookieStr := strings.TrimSpace(match[1])
			if existingCookie := data.Headers.Get("Cookie"); existingCookie != "" {
				data.Headers.Add("Cookie", existingCookie+"; "+cookieStr)
			} else {
				data.Headers.Add("Cookie", cookieStr)
			}
		}
	}

	// æ›¿æ¢ Referer
	if referer := data.Headers.Get("Referer"); referer != "" {
		data.Headers.Set("Referer", strings.ReplaceAll(referer, bookID, "%s"))
	}

	return data, nil
}

func NewRequestViaCurl(data CurlData, bookID string, page int) (*http.Request, error) {
	bookUrl := fmt.Sprintf(data.PageURLFormat, bookID, page)

	req, err := http.NewRequest(http.MethodGet, bookUrl, nil)
	if err != nil {
		return nil, err
	}

	headers := data.Headers.Clone()
	if referer := headers.Get("Referer"); referer != "" {
		headers.Set("Referer", fmt.Sprintf(referer, bookID))
	}
	req.Header = headers

	return req, nil
}

func (d *Download) HandlerRequest(ctx *cli.Context, dl *Downloader) {
	dl.PrintLog("Download-HandlerRequest", "å¼€å§‹æ‰§è¡Œ")
	if d.IsCanHandler(ctx, dl) {
		dl.ZLog.Info().Msg("ğŸš¨ğŸš¨ğŸš¨æ­£åœ¨ç”Ÿæˆä¸­è¯·ç¨ç­‰.....ğŸš¨ğŸš¨ğŸš¨")
		curl := dl.authenticatedCurl
		curlData, err := ParseCURL(strings.TrimSpace(curl))
		if err != nil {
			dl.PrintLog("ParseCURL", "è§£æè®¤è¯è¯·æ±‚\n"+curl+"\nå¤±è´¥", err)

			dl.err = errors.New("è§£æè®¤è¯è¯·æ±‚\n" + curl + "\nå¤±è´¥")
			return
		}
		for _, item := range dl.paths {
			var images []string
			path := dl.imagesTmpDir + dl.pathKey + "/" + item.Remark + "/"
			if err := os.MkdirAll(path, 0777); err != nil {
				dl.PrintLog("os.MkdirAll", "åˆ›å»ºç›®å½•"+path+"å¤±è´¥,è¯·é‡è¯•!", err)
				dl.err = errors.New("åˆ›å»ºç›®å½•" + path + "å¤±è´¥,è¯·é‡è¯•!")
				return
			}

			for i := 1; i <= item.Pages; i++ {
				bookID := item.BookID
				// check file exists
				filename := fmt.Sprintf("%s%d.jpg", path, i)
				if _, err := os.Stat(filename); err == nil {
					images = append(images, filename)
					continue
				}

				bookPageURL := fmt.Sprintf(curlData.PageURLFormat, bookID, i)
				req, err := NewRequestViaCurl(curlData, bookID, i)
				if err != nil {
					dl.PrintLog("http.NewRequest", "åˆ›å»ºè¯·æ±‚"+bookPageURL+"å¤±è´¥", err)

					dl.err = errors.New("è¯·æ±‚" + bookPageURL + "å¤±è´¥")
					return
				}
				resp, err := http.DefaultClient.Do(req)
				if err != nil {
					dl.PrintLog("http.Get", "è¯·æ±‚"+bookPageURL+"å¤±è´¥", err)

					dl.err = errors.New("è¯·æ±‚" + bookPageURL + "å¤±è´¥")
					return
				}
				defer func() {
					resp.Body.Close()
				}()

				// check image
				if !strings.Contains(resp.Header.Get("Content-Type"), "image") {
					dl.PrintLog("Content-Type", "ç”µå­ä¹¦urlè¿”å›"+bookPageURL+"éå›¾ç‰‡,è®¤è¯è¯·æ±‚å·²è¿‡æœŸ", err)

					dl.err = errors.New("ç”µå­ä¹¦urlè¿”å›" + bookPageURL + "éå›¾ç‰‡,è®¤è¯è¯·æ±‚å·²è¿‡æœŸ")
					return
				}

				contents, err := io.ReadAll(resp.Body)

				if err != nil {
					dl.PrintLog("io.ReadAll", "è¯»å–ç”µå­ä¹¦url"+bookPageURL+"å†…å®¹å¤±è´¥", err)

					dl.err = errors.New("è¯»å–ç”µå­ä¹¦url" + bookPageURL + "å†…å®¹å¤±è´¥")
					return
				}

				if err = os.WriteFile(filename, contents, 0666); err != nil {
					dl.PrintLog("os.WriteFile", "å†™å…¥ç”µå­ä¹¦å†…å®¹åˆ°"+filename+"å¤±è´¥", err)

					dl.err = errors.New("å†™å…¥ç”µå­ä¹¦å†…å®¹åˆ°" + filename + "å¤±è´¥")
					return
				}

				images = append(images, filename)

				dl.PrintLog("download ok", bookPageURL, "ç¬¬", i, "é¡µå¤„ç†å®Œæˆ")

				time.Sleep(time.Duration(1+rand.Intn(3)) * time.Second)
			}

			if len(images) > 0 {
				if len(item.Remark) == 0 {
					dl.images[dl.subject] = images
				} else {
					dl.images[item.Remark] = images
				}
			}
		}
	}

	d.NextHandler.HandlerRequest(ctx, dl)
}

func (d *Download) IsCanHandler(ctx *cli.Context, dl *Downloader) bool {
	dl.PrintLog("Download-IsCanHandler", "dl.err=", dl.err, "dl.image=", len(dl.images))

	return dl.err == nil
}
